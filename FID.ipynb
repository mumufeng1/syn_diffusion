{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as T\n",
    "import torch\n",
    "from IPython.display import display\n",
    "import torch.nn as nn\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.utils import save_image\n",
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn.modules.activation import ReLU\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm_notebook\n",
    "from torchvision.utils import save_image\n",
    "import matplotlib\n",
    "import math\n",
    "from inspect import isfunction\n",
    "from functools import partial\n",
    "import scipy\n",
    "from scipy.special import rel_entr\n",
    "from torch import nn, einsum\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from einops import rearrange\n",
    "from einops.layers.torch import Rearrange\n",
    "from torch import nn, einsum\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.image as mpimg\n",
    "import glob\n",
    "from PIL import Image\n",
    "from itertools import product\n",
    "import random\n",
    "from FID_helper import *\n",
    "import random\n",
    "from scipy.linalg import sqrtm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "def load_data(dataset_name, seq_len, sample_num):\n",
    "    seq = np.load(dataset_name, allow_pickle=True)\n",
    "    seq = seq.tolist()\n",
    "    random.seed(3)\n",
    "    seq_sample = random.sample(seq, sample_num)\n",
    "\n",
    "    return  seq2onehot(seq_sample, seq_len)\n",
    "\n",
    "\n",
    "def get_1d_fid_score(syn_seq_name, nat_seq_name, model_1d, seq_len):\n",
    "    sample_num = 1000\n",
    "    syn_seq = load_data(syn_seq_name, seq_len, sample_num)\n",
    "    nat_seq = load_data(nat_seq_name, seq_len, sample_num)\n",
    "\n",
    "    nat_seq_1d = nat_seq.reshape(sample_num, 4, seq_len)\n",
    "    nat_seq_1d = train_dataset(nat_seq_1d)\n",
    "    nat_seq_1d = DataLoader(nat_seq_1d)\n",
    "\n",
    "    syn_seq_1d = syn_seq.reshape(sample_num, 4, seq_len)\n",
    "    syn_seq_1d = train_dataset(syn_seq_1d)\n",
    "    syn_seq_1d = DataLoader(syn_seq_1d)\n",
    "\n",
    "    fea_nat_1d = np.zeros((1,256), dtype=float)\n",
    "    for data in nat_seq_1d:\n",
    "        fea = model_1d(data['feature'] )\n",
    "        fea_nat_1d = np.append(fea_nat_1d, fea.detach().numpy(), axis=0)\n",
    "    fea_nat_1d = np.delete(fea_nat_1d, 0, axis=0)\n",
    "\n",
    "    fea_syn_1d = np.zeros((1,256), dtype=float)\n",
    "    for data in syn_seq_1d:\n",
    "        fea = model_1d(data['feature'] )\n",
    "        fea_syn_1d = np.append(fea_syn_1d, fea.detach().numpy(), axis=0)\n",
    "    fea_syn_1d = np.delete(fea_syn_1d, 0, axis=0)\n",
    "\n",
    "    mus_nat_1d = fea_nat_1d.mean(axis=0)\n",
    "    mus_syn_1d = fea_syn_1d.mean(axis=0)\n",
    "    var_nat_1d = np.cov(fea_nat_1d , rowvar=False)\n",
    "    var_syn_1d = np.cov(fea_syn_1d , rowvar=False)\n",
    "\n",
    "    ssdiff = np.sum((mus_nat_1d - mus_syn_1d)**2.0)\n",
    "    print(f\"ssdiff {ssdiff}\")\n",
    "    covmean = sqrtm(var_nat_1d.dot(var_syn_1d))\n",
    "    print(f\"covmean {covmean}\")\n",
    "    if np.iscomplexobj(covmean):\n",
    "        covmean = covmean.real\n",
    "    fid_1d = ssdiff + np.trace(var_nat_1d + var_syn_1d - 2.0 * covmean)\n",
    "\n",
    "    return  fid_1d\n",
    "\n",
    "\n",
    "def get_2d_fid_score(syn_seq_name, nat_seq_name, seq_len, model_2d, dim):\n",
    "    sample_num = 1000\n",
    "    syn_seq = load_data(syn_seq_name, seq_len, sample_num)\n",
    "    nat_seq = load_data(nat_seq_name, seq_len, sample_num)\n",
    "\n",
    "    nat_seq_2d = nat_seq.reshape(sample_num, seq_len, 4, 1)\n",
    "    nat_seq_2d = train_dataset(nat_seq_2d)\n",
    "    nat_seq_2d = DataLoader(nat_seq_2d, batch_size=1024)\n",
    "\n",
    "    syn_seq_2d = syn_seq.reshape(sample_num, seq_len, 4, 1)\n",
    "    syn_seq_2d = train_dataset(syn_seq_2d)\n",
    "    syn_seq_2d = DataLoader(syn_seq_2d, batch_size=1024)\n",
    "\n",
    "    # model_2d = PREDICT_2D()\n",
    "    # model_2d.load_state_dict(torch.load(model_name))\n",
    "\n",
    "    fea_nat_2d = np.zeros((1, dim), dtype=float)\n",
    "    for data in nat_seq_2d:\n",
    "        fea = model_2d(data['feature'])\n",
    "        fea_nat_2d = np.append(fea_nat_2d, fea.detach().numpy(), axis=0)\n",
    "    fea_nat_2d = np.delete(fea_nat_2d, 0, axis=0)\n",
    "\n",
    "    fea_syn_2d = np.zeros((1, dim), dtype=float)\n",
    "    for data in syn_seq_2d:\n",
    "        fea = model_2d(data['feature'] )\n",
    "        fea_syn_2d = np.append(fea_syn_2d, fea.detach().numpy(), axis=0)\n",
    "    fea_syn_2d = np.delete(fea_syn_2d, 0, axis=0)\n",
    "\n",
    "    mus_nat_2d = fea_nat_2d.mean(axis=0)\n",
    "    mus_syn_2d = fea_syn_2d.mean(axis=0)\n",
    "    var_nat_2d = np.cov(fea_nat_2d , rowvar=False)\n",
    "    var_syn_2d = np.cov(fea_syn_2d , rowvar=False)\n",
    "\n",
    "    ssdiff = np.sum((mus_nat_2d - mus_syn_2d)**2.0)\n",
    "    # print(f\"ssdiff {ssdiff}\")\n",
    "    covmean = sqrtm(var_nat_2d.dot(var_syn_2d))\n",
    "    # print(f\"covmean {covmean}\")\n",
    "    if np.iscomplexobj(covmean):\n",
    "        covmean = covmean.real\n",
    "    fid_2d = ssdiff + np.trace(var_nat_2d + var_syn_2d - 2.0 * covmean)\n",
    "    # print(fid_2d)\n",
    "    return fid_2d\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'syn_seq/promoter_1/seq_epoch_24.npy'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 41\u001B[0m\n\u001B[0;32m     39\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m130\u001B[39m):\n\u001B[0;32m     40\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m i \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m25\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m24\u001B[39m:\n\u001B[1;32m---> 41\u001B[0m         dif_fid\u001B[38;5;241m.\u001B[39mappend(\u001B[43mget_2d_fid_score\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43msyn_seq/promoter_1/seq_epoch_\u001B[39;49m\u001B[38;5;132;43;01m{}\u001B[39;49;00m\u001B[38;5;124;43m.npy\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mformat\u001B[49m\u001B[43m(\u001B[49m\u001B[43mi\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdata/promoter_1.npy\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m50\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m400\u001B[39;49m\u001B[43m)\u001B[49m)\n\u001B[0;32m     42\u001B[0m         gan_fid\u001B[38;5;241m.\u001B[39mappend(get_2d_fid_score(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgan_seq/promoter_1/seq_epoch_\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m.npy\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(i), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdata/promoter_1.npy\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m50\u001B[39m, model, \u001B[38;5;241m400\u001B[39m))\n",
      "Cell \u001B[1;32mIn[2], line 55\u001B[0m, in \u001B[0;36mget_2d_fid_score\u001B[1;34m(syn_seq_name, nat_seq_name, seq_len, model_2d, dim)\u001B[0m\n\u001B[0;32m     53\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_2d_fid_score\u001B[39m(syn_seq_name, nat_seq_name, seq_len, model_2d, dim):\n\u001B[0;32m     54\u001B[0m     sample_num \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1000\u001B[39m\n\u001B[1;32m---> 55\u001B[0m     syn_seq \u001B[38;5;241m=\u001B[39m \u001B[43mload_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43msyn_seq_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mseq_len\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_num\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     56\u001B[0m     nat_seq \u001B[38;5;241m=\u001B[39m load_data(nat_seq_name, seq_len, sample_num)\n\u001B[0;32m     58\u001B[0m     nat_seq_2d \u001B[38;5;241m=\u001B[39m nat_seq\u001B[38;5;241m.\u001B[39mreshape(sample_num, seq_len, \u001B[38;5;241m4\u001B[39m, \u001B[38;5;241m1\u001B[39m)\n",
      "Cell \u001B[1;32mIn[2], line 2\u001B[0m, in \u001B[0;36mload_data\u001B[1;34m(dataset_name, seq_len, sample_num)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload_data\u001B[39m(dataset_name, seq_len, sample_num):\n\u001B[1;32m----> 2\u001B[0m     seq \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mallow_pickle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m     seq \u001B[38;5;241m=\u001B[39m seq\u001B[38;5;241m.\u001B[39mtolist()\n\u001B[0;32m      4\u001B[0m     seq_sample \u001B[38;5;241m=\u001B[39m random\u001B[38;5;241m.\u001B[39msample(seq, sample_num)\n",
      "File \u001B[1;32mD:\\software\\Anaconda\\envs\\torch\\lib\\site-packages\\numpy\\lib\\npyio.py:407\u001B[0m, in \u001B[0;36mload\u001B[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001B[0m\n\u001B[0;32m    405\u001B[0m     own_fid \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m    406\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 407\u001B[0m     fid \u001B[38;5;241m=\u001B[39m stack\u001B[38;5;241m.\u001B[39menter_context(\u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mos_fspath\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m)\n\u001B[0;32m    408\u001B[0m     own_fid \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    410\u001B[0m \u001B[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001B[39;00m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'syn_seq/promoter_1/seq_epoch_24.npy'"
     ]
    }
   ],
   "source": [
    "class PREDICT_1(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(50, 100, kernel_size=(6, 1), padding=(3, 0)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 1))\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(100, 200, kernel_size=(5, 1), padding=(3, 0)),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(200, 200, kernel_size=(6, 1), padding=(3, 0)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 1)),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(400, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        # x = self.fc(x)\n",
    "        # x = x.squeeze(-1)\n",
    "        # x = x.squeeze(-1)\n",
    "        return x\n",
    "\n",
    "model = PREDICT_1()\n",
    "model.load_state_dict(torch.load('fid_model/promoter_1/CNN_train.pth'))\n",
    "dif_fid = []\n",
    "gan_fid = []\n",
    "for i in range(130):\n",
    "    if i % 25 == 24:\n",
    "        dif_fid.append(get_2d_fid_score(\"syn_seq/promoter_1/seq_epoch_{}.npy\".format(i), \"data/promoter_1.npy\", 50, model, 400))\n",
    "        gan_fid.append(get_2d_fid_score(\"gan_seq/promoter_1/seq_epoch_{}.npy\".format(i), \"data/promoter_1.npy\", 50, model, 400))\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class PREDICT_2(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(165, 300, kernel_size=(6, 1), padding=(3, 0)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 1))\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(300, 600, kernel_size=(5, 1), padding=(3, 0)),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(600, 600, kernel_size=(6, 1), padding=(3, 0)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 1)),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(1200, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        # x = self.fc(x)\n",
    "        # x = x.squeeze(-1)\n",
    "        # x = x.squeeze(-1)\n",
    "        return x\n",
    "\n",
    "model = PREDICT_2()\n",
    "model.load_state_dict(torch.load('fid_model/promoter_2/CNN_train.pth'))\n",
    "dif_fid = []\n",
    "gan_fid = []\n",
    "for i in range(130):\n",
    "    if i % 25 == 24:\n",
    "        dif_fid.append(get_2d_fid_score(\"syn_seq/promoter_2/seq_epoch_{}.npy\".format(i), \"data/promoter_2.npy\", 165, model, 1200))\n",
    "        gan_fid.append(get_2d_fid_score(\"gan_seq/promoter_2/seq_epoch_{}.npy\".format(i), \"data/promoter_2.npy\", 165, model, 1200))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "[0.14667508270770965,\n 0.1371422848951489,\n 0.15874560439821428,\n 0.13899011367347583,\n 0.13647543427678344]"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dif_fid\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "[0.34555065855256617,\n 0.21908250867339132,\n 0.21942269444060641,\n 0.21668955356713365,\n 0.22539711609990742]"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gan_fid"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "class PREDICT_3(nn.Module):\n",
    "\n",
    "    # 卷积层结构卷积-ReLU-池化-卷积-ReLU-卷积-ReLU-池化-全连接-ReLU-全连接\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(118, 200, kernel_size=(6, 1), padding=(3, 0)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 1))\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(200, 400, kernel_size=(5, 1), padding=(3, 0)),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(400, 400, kernel_size=(6, 1), padding=(3, 0)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 1)),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(800, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        # x = self.fc(x)\n",
    "        # x = x.squeeze(-1)\n",
    "        # x = x.squeeze(-1)\n",
    "        return x\n",
    "\n",
    "model = PREDICT_3()\n",
    "model.load_state_dict(torch.load('fid_model/promoter_3/CNN_train.pth'))\n",
    "dif_fid = []\n",
    "gan_fid = []\n",
    "for i in range(130):\n",
    "    if i % 25 == 24:\n",
    "        dif_fid.append(get_2d_fid_score(\"syn_seq/promoter_3/seq_epoch_{}.npy\".format(i), \"data/promoter_3.npy\", 118, model, 800))\n",
    "        gan_fid.append(get_2d_fid_score(\"gan_seq/promoter_3/seq_epoch_{}.npy\".format(i), \"data/promoter_3.npy\", 118, model, 800))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "[0.14602551439108105,\n 0.6514319866414572,\n 0.14433246545097428,\n 0.1128892669418097,\n 0.15756700881187558]"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dif_fid"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "[0.9759876493436314,\n 0.9803591615712742,\n 1.2300523329491055,\n 1.2796727514867205,\n 1.6413831349875943]"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gan_fid"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "class PREDICT(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(50, 100, kernel_size=(6, 1), padding=(3, 0)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 1))\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(100, 200, kernel_size=(5, 1), padding=(3, 0)),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(200, 200, kernel_size=(6, 1), padding=(3, 0)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 1)),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(400, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        # x = self.fc(x)\n",
    "        # x = x.squeeze(-1)\n",
    "        # x = x.squeeze(-1)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = PREDICT_1()\n",
    "model.load_state_dict(torch.load('fid_model/promoter_1/CNN_train.pth'))\n",
    "dif_fid = []\n",
    "gan_fid = []\n",
    "for i in range(130):\n",
    "    if i % 25 == 24:\n",
    "        dif_fid.append(get_2d_fid_score(\"syn_seq/promoter_1/seq_epoch_{}.npy\".format(i), \"data/promoter_1.npy\", 50, model, 400))\n",
    "        gan_fid.append(get_2d_fid_score(\"gan_seq/promoter_1/seq_epoch_{}.npy\".format(i), \"data/promoter_1.npy\", 50, model, 400))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "[0.018770344171487766,\n 0.020423965282888923,\n 0.018673418506755985,\n 0.019368654406041647,\n 0.018937890635125194]"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dif_fid"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "[0.02863051575390797,\n 0.019944700622179422,\n 0.02190636098476251,\n 0.020911923764308893,\n 0.021484443022301743]"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gan_fid"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dif_fid_list = [[0.018770344171487766,\n",
    "                 0.020423965282888923,\n",
    "                 0.018673418506755985,\n",
    "                 0.019368654406041647,\n",
    "                 0.018937890635125194],\n",
    "                ]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "promoter_1\n",
      "ep.\t gan\t dif\n",
      "10\t 0.0840\t 0.0197\n",
      "20\t 0.0275\t 0.0190\n",
      "30\t 0.0234\t 0.0191\n",
      "40\t 0.0250\t 0.0185\n",
      "50\t 0.0202\t 0.0187\n",
      "60\t 0.0205\t 0.0183\n",
      "70\t 0.0198\t 0.0182\n",
      "80\t 0.0207\t 0.0185\n",
      "90\t 0.0200\t 0.0187\n",
      "100\t 0.0199\t 0.0187\n",
      "110\t 0.0202\t 0.0183\n",
      "120\t 0.0200\t 0.0194\n",
      "130\t 0.0216\t 0.0186\n",
      "promoter_2\n",
      "ep.\t gan\t dif\n",
      "10\t 11.6918\t 0.1816\n",
      "20\t 0.2844\t 0.2169\n",
      "30\t 0.3218\t 0.1390\n",
      "40\t 0.3766\t 0.1641\n",
      "50\t 0.4111\t 0.1394\n",
      "60\t 0.1870\t 0.1893\n",
      "70\t 0.2056\t 0.1467\n",
      "80\t 0.1894\t 0.1484\n",
      "90\t 0.1772\t 0.1771\n",
      "100\t 0.2241\t 0.1398\n",
      "110\t 0.1907\t 0.1408\n",
      "120\t 0.1747\t 0.1720\n",
      "130\t 0.2097\t 0.1372\n",
      "promoter_3\n",
      "ep.\t gan\t dif\n",
      "10\t 1.7199\t 0.5522\n",
      "20\t 0.7258\t 0.2623\n",
      "30\t 0.4541\t 0.2406\n",
      "40\t 1.1713\t 0.1882\n",
      "50\t 0.9300\t 0.6210\n",
      "60\t 0.5698\t 0.3733\n",
      "70\t 0.7089\t 0.1547\n",
      "80\t 0.8405\t 0.1237\n",
      "90\t 1.0051\t 0.1357\n",
      "100\t 0.9378\t 0.0958\n",
      "110\t 0.7684\t 0.3367\n",
      "120\t 0.7943\t 0.4636\n",
      "130\t 0.7276\t 0.1597\n"
     ]
    }
   ],
   "source": [
    "class PREDICT_1(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(50, 100, kernel_size=(6, 1), padding=(3, 0)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 1))\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(100, 200, kernel_size=(5, 1), padding=(3, 0)),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(200, 200, kernel_size=(6, 1), padding=(3, 0)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 1)),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(400, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        # x = self.fc(x)\n",
    "        # x = x.squeeze(-1)\n",
    "        # x = x.squeeze(-1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class PREDICT_2(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(165, 300, kernel_size=(6, 1), padding=(3, 0)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 1))\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(300, 600, kernel_size=(5, 1), padding=(3, 0)),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(600, 600, kernel_size=(6, 1), padding=(3, 0)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 1)),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(1200, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        # x = self.fc(x)\n",
    "        # x = x.squeeze(-1)\n",
    "        # x = x.squeeze(-1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class PREDICT_3(nn.Module):\n",
    "\n",
    "    # 卷积层结构卷积-ReLU-池化-卷积-ReLU-卷积-ReLU-池化-全连接-ReLU-全连接\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(118, 200, kernel_size=(6, 1), padding=(3, 0)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 1))\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(200, 400, kernel_size=(5, 1), padding=(3, 0)),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(400, 400, kernel_size=(6, 1), padding=(3, 0)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 1)),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(800, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        # x = self.fc(x)\n",
    "        # x = x.squeeze(-1)\n",
    "        # x = x.squeeze(-1)\n",
    "        return x\n",
    "\n",
    "\n",
    "model_1 = PREDICT_1()\n",
    "model_1.load_state_dict(torch.load('fid_model/promoter_1/CNN_train.pth'))\n",
    "\n",
    "model_2 = PREDICT_2()\n",
    "model_2.load_state_dict(torch.load('fid_model/promoter_2/CNN_train.pth'))\n",
    "\n",
    "model_3 = PREDICT_3()\n",
    "model_3.load_state_dict(torch.load('fid_model/promoter_3/CNN_train.pth'))\n",
    "\n",
    "seq_len = [50, 165, 118]\n",
    "\n",
    "dim = [400, 1200, 800]\n",
    "\n",
    "dif_fid = []\n",
    "gan_fid = []\n",
    "\n",
    "e = 1\n",
    "gan_fid_temp = []\n",
    "dif_fid_temp = []\n",
    "print(\"promoter_{}\".format(e))\n",
    "print(\"ep.\\t gan\\t dif\")\n",
    "for i in range(130):\n",
    "        if i % 10 == 9:\n",
    "            dif_fid_temp.append(get_2d_fid_score(\"syn_seq/promoter_{}/new_seq_epoch_{}.npy\".format(e, i), \"data/promoter_{}.npy\".format(e), seq_len[e-1], model_1, dim[e-1]))\n",
    "            gan_fid_temp.append(get_2d_fid_score(\"gan_seq/promoter_{}/samples_{}.npy\".format(e, i), \"data/promoter_{}.npy\".format(e), seq_len[e-1], model_1, dim[e-1]))\n",
    "            print(\"{}\\t {:.4f}\\t {:.4f}\".format(i+1, gan_fid_temp[-1], dif_fid_temp[-1]))\n",
    "gan_fid.append(gan_fid_temp)\n",
    "dif_fid.append(dif_fid_temp)\n",
    "\n",
    "\n",
    "e = 2\n",
    "gan_fid_temp = []\n",
    "dif_fid_temp = []\n",
    "print(\"promoter_{}\".format(e))\n",
    "print(\"ep.\\t gan\\t dif\")\n",
    "for i in range(130):\n",
    "        if i % 10 == 9:\n",
    "            dif_fid_temp.append(get_2d_fid_score(\"syn_seq/promoter_{}/new_seq_epoch_{}.npy\".format(e, i), \"data/promoter_{}.npy\".format(e), seq_len[e-1], model_2, dim[e-1]))\n",
    "            gan_fid_temp.append(get_2d_fid_score(\"gan_seq/promoter_{}/samples_{}.npy\".format(e, i), \"data/promoter_{}.npy\".format(e), seq_len[e-1], model_2, dim[e-1]))\n",
    "            print(\"{}\\t {:.4f}\\t {:.4f}\".format(i+1, gan_fid_temp[-1], dif_fid_temp[-1]))\n",
    "gan_fid.append(gan_fid_temp)\n",
    "dif_fid.append(dif_fid_temp)\n",
    "\n",
    "e = 3\n",
    "gan_fid_temp = []\n",
    "dif_fid_temp = []\n",
    "print(\"promoter_{}\".format(e))\n",
    "print(\"ep.\\t gan\\t dif\")\n",
    "for i in range(130):\n",
    "        if i % 10 == 9:\n",
    "            dif_fid_temp.append(get_2d_fid_score(\"syn_seq/promoter_{}/new_seq_epoch_{}.npy\".format(e, i), \"data/promoter_{}.npy\".format(e), seq_len[e-1], model_3, dim[e-1]))\n",
    "            gan_fid_temp.append(get_2d_fid_score(\"gan_seq/promoter_{}/samples_{}.npy\".format(e, i), \"data/promoter_{}.npy\".format(e), seq_len[e-1], model_3, dim[e-1]))\n",
    "            print(\"{}\\t {:.4f}\\t {:.4f}\".format(i+1, gan_fid_temp[-1], dif_fid_temp[-1]))\n",
    "gan_fid.append(gan_fid_temp)\n",
    "dif_fid.append(dif_fid_temp)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
